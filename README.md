<p align="center">
  <img src="https://img.shields.io/github/license/yourusername/celebmind?color=blue" alt="License Badge">
  <img src="https://img.shields.io/github/stars/yourusername/celebmind?style=social" alt="GitHub Stars">
</p>

<h1 align="center">ğŸ¬ CelebMind: Celebrity Detector & Q&A App</h1>

<p align="center">
  An intelligent AI app that <strong>detects celebrities from uploaded images</strong> and answers user queries about them using <strong>Groq's Llama 3 LLM</strong>. Built with <strong>OpenCV</strong>, <strong>Flask</strong>, and <strong>Kubernetes</strong> for scalable deployment.
</p>

---

## ğŸ“Œ Features

- ğŸ§  **LLM-Powered Q&A**: Asks questions about the detected celebrity using Groq's Llama 3 model.
- ğŸ§â€â™‚ï¸ **Celebrity Detection**: Uses OpenCV to detect and identify celebrities from uploaded photos.
- ğŸš€ **Real-time Inference**: Instant answers from LLM served via Flask API.
- ğŸ“¦ **Dockerized Microservice**: Containerized and deployable across any environment.
- â˜¸ï¸ **Kubernetes Ready**: GKE deployment with CircleCI for CI/CD.
- ğŸ”’ **Secure & Lightweight**: Environment variable support with `.env` and optimized image.

---

## ğŸ§± Architecture

```mermaid
graph TD
    A[User Uploads Image] --> B[Flask Backend]
    B --> C[OpenCV: Celebrity Detection]
    B --> D[Groq API Call for LLM Answer]
    C --> E[Detected Celebrity Name]
    D --> F[Answer to Question]
    E --> G[Display Response on UI]
    F --> G
```

## ğŸ”„ Project Workflow
```mermaid
graph TD
    A[ğŸ§‘ User Uploads Image] --> B[ğŸ–¼ï¸ Flask Backend Receives Image]
    B --> C[ğŸ§  OpenCV Face Detection + Matching]
    C --> D[âœ… Celebrity Identified]

    D --> E[ğŸ“ User Enters Question]
    E --> F[ğŸ§© Prompt Construction]
    F --> G[ğŸš€ Groq LLaMA 3.1-70B API Call]

    G --> H[ğŸ’¡ LLM Generates Answer]
    H --> I[ğŸŒ Flask Sends Response]
    I --> J[ğŸ–¥ï¸ Frontend Displays Result]

    J --> K[ğŸ” CircleCI CI/CD Pipeline]
    K --> L[ğŸ³ Docker Build & Push to GCP Registry]
    L --> M[Kubernetes Deploy to GKE]

```
## ğŸ”„ Step-By-Step : How it works?

The **CelebMind** project follows a streamlined workflow to deliver fast, intelligent celebrity detection and Q&A using LLMs:

---

### 1. ğŸ–¼ï¸ User Uploads an Image
- The user provides an image via the frontend interface.
- The image is sent to the Flask backend API.

---

### 2. ğŸ§  Celebrity Detection (OpenCV)
- The backend uses **OpenCV** to analyze facial features.
- It matches the image with a pre-defined celebrity dataset (embeddings or templates).
- If a match is found, the **celebrity's name is extracted**.

---

### 3. â“ User Submits a Question
- The user types a **natural-language question** related to the celebrity.
- The question and the detected celebrity name are **combined into a single prompt**.

---

### 4. âš¡ Groq LLM API (LLaMA 3.1 70B)
- The composed prompt is sent to **Groq's ultra-fast inference API** using the `llama3-70b-qa` model.
- The model generates an **intelligent and context-aware answer**.

---

### 5. ğŸ› ï¸ Flask Response Rendering
- The LLM response is sent back to the Flask server.
- Flask renders the result along with:
  - The detected image
  - The celebrity name

---

### 6. ğŸ’» Frontend Display
The UI displays:
- âœ… Detected celebrity photo and name  
- âœ… User's original question  
- âœ… LLM-generated answer  

---

### 7. ğŸš€ CI/CD & Deployment
- Code is pushed to **GitHub**
- **CircleCI pipeline**:
  - Builds Docker image
  - Pushes image to **GCP Artifact Registry**
  - Deploys to **Google Kubernetes Engine (GKE)** using `kubectl`

---

## ğŸ§ª Tech Stack
| Area       | Tools & Frameworks               |
| ---------- | -------------------------------- |
| Backend    | Flask, Python                    |
| Frontend   | HTML/CSS, JS (simple templating) |
| ML / AI    | OpenCV, Groq API (LLaMA-3.1 70B) |
| Deployment | Docker, Kubernetes (GKE)         |
| CI/CD      | CircleCI, GitHub                 |
| Infra      | GCP VM, GKE, Container Registry  |

---
## ğŸš€ Setup Instructions
### 1ï¸âƒ£ Clone the repo
```bash
git clone https://github.com/aimldinesh/celebmind.git
cd celebmind
```
### 2ï¸âƒ£ Create and Activate Virtual Environment
```bash
python -m venv venv
source venv/bin/activate  # On Windows: venv\Scripts\activate
```
### 3ï¸âƒ£ Install dependencies
```bash
pip install -e .
```
### 4ï¸âƒ£ Set environment variables
Create a .env file:
```bash
GROQ_API_KEY = ""
```
### 5. Run locally
```bash
python app.py
```
The app will be available at: http://127.0.0.1:5000

---
## âœ… Docker Run (Optional)
```bash
docker build -t celebmind-app .
docker run -p 5000:5000 celebmind-app
```
## ğŸ“¸ Sample Output

---
## ğŸ“š Future Improvements

- âœ… **Add multiple celebrity support**  
- âœ… **Enhance UI styling**  
- ğŸ”œ **Add Redis caching for Q&A**  
- ğŸ”œ **Integrate voice-based question input**

---
## ğŸ’¡ Credits
- Groq API (LLaMA 3)
- OpenCV for computer vision
- Flask for backend
- Kubernetes on GKE

---
## ğŸ¤ Contributors
- [Dinesh](https://github.com/aimldinesh)

